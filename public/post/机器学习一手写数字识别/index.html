<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>机器学习一:手写数字识别 - </title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="手写数字识别 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 import gzip import pickle import numpy as np import torch import torch.nn.functional as F from PIL import Image from torch import nn from torch import optim from torch.utils.data import DataLoader from torch.utils.data import TensorDataset from torchvision import transforms # https://raw.githubusercontent.com/mnielsen/neural-networks-and-deep-learning/master/data/mnist.pkl.gz # 从文件中加载数据 with gzip.open(&#34;mnist.pkl.gz&#34;, &#34;rb&#34;) as f: # 使用 pickle 加载数据，数据包括训练集、验证集和测试集 # 这里我们只加载了训练集和验证集 (x_train, y_train), (x_valid, y_valid), _ = pickle.load(f, encoding=&#34;latin-1&#34;) # 将加载的数据转换为 PyTorch 张量 x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid)) # 定义神经网络模型 class Mnist(nn.Module): def __init__(self): super().__init__() # 定义神经网络的层 self.hidden1 = nn.Linear(784, 128) # 隐藏层1，输入大小为 784，输出大小为 128 self.hidden2 = nn.Linear(128, 256) # 隐藏层2，输入大小为 128，输出大小为 256 self.out = nn.Linear(256, 10) # 输出层，输入大小为 256，输出大小为 10 self.dropout = nn.Dropout(0.5) # 定义 Dropout 层，丢弃概率为 0.5 def forward(self, x): # 定义数据流向 x = F.relu(self.hidden1(x)) # 使用 ReLU 激活函数 x = self.dropout(x) x = F.relu(self.hidden2(x)) x = self.dropout(x) x = self.out(x) return x # 定义训练函数 def fit(steps, loss_func, train_dl, valid_dl): # 创建神经网络模型 model = Mnist() # 定义优化器 opt = optim.Adam(model.parameters(), lr=0.001) for step in range(steps): model.train() # 将模型设置为训练模式 for xb, yb in train_dl: loss_batch(model, loss_func, xb, yb, opt) # 计算并更新模型参数 model.eval() # 将模型设置为评估模式 with torch.no_grad(): # 不更新权重参数 # 在验证集上进行评估 loss_result = [loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl] losses, nums = zip(*loss_result) val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums) correct = 0 total = 0 for xb, yb in valid_dl: outputs = model(xb) _, predicted = torch.max(outputs.data, 1) # 最大值和索引 total &#43;= yb.size(0) correct &#43;= (predicted == yb).sum().item() print(f&#34;当前step: {step}, 验证集损失: {val_loss} 准确率 {100 * correct / total}%&#34;) return model # 返回训练好的模型 # 定义计算损失的函数 def loss_batch(model, loss_func, xb, yb, opt=None): loss = loss_func(model(xb), yb) # 计算损失 if opt is not None: loss.backward() # 反向传播计算梯度 opt.step() # 更新模型权重参数 opt.zero_grad() # 梯度清零 return loss.item(), len(xb) # 定义预测函数 def predict(model, image_path): # 定义图像的预处理 transform = transforms.Compose([ transforms.Grayscale(), # 转为灰度图 transforms.Resize((28, 28)), # 调整大小为28x28 transforms.ToTensor(), # 转为张量 transforms.Normalize((0.5,), (0.5,)) # 归一化 ]) # 打开图像 img = Image.open(image_path) img = transform(img).unsqueeze(0) # 添加批次维度 # 将模型设置为评估模式 model.eval() with torch.no_grad(): output = model(img.view(-1, 28 * 28)) # 展平图像并进行预测 _, predicted = torch.max(output, 1) # 获取最大值对应的索引 return predicted.item() if __name__ == &#39;__main__&#39;: bs = 64 # 定义批量大小 # 创建训练集和验证集的 DataLoader 对象 train_dl = DataLoader(TensorDataset(x_train, y_train), batch_size=bs, shuffle=True) valid_dl = DataLoader(TensorDataset(x_valid, y_valid), batch_size=bs) # 训练模型 model = fit(25, F.cross_entropy, train_dl, valid_dl) # 保存模型参数 torch.save(model.state_dict(), &#39;mnist_model.pth&#39;) # 创建模型实例并加载训练好的模型参数 model = Mnist() model.load_state_dict(torch.load(&#39;mnist_model.pth&#39;)) # 预测手写数字图像 image_path = &#39;test.png&#39; # 替换为你要预测的图像路径 predicted_digit = predict(model, image_path) print(f&#39;预测的数字是: {predicted_digit}&#39;) 温度预测 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 import pandas as pd import torch from sklearn import preprocessing # 数据预处理模块 # https://github.com/DevCHyderabad/Data-Science/blob/master/ml_algorithms/randomForrest/temps.csv # 数据加载 features = pd.read_csv(&#34;temps.csv&#34;) # 将日期转换为datetime格式 dates = pd.to_datetime(features[[&#39;year&#39;, &#39;month&#39;, &#39;day&#39;]]) # 将分类特征转化为数值形式 features = pd.get_dummies(features) # 标签列 labels = features[&#34;actual&#34;].values # 在特征中去除标签列 features = features.drop(&#34;actual&#34;, axis=1) # 标准化特征数据 scaler = preprocessing.StandardScaler() input_features = scaler.fit_transform(features) # 转换数据格式为Tensor # 定义模型参数 input_size = input_features.shape[1] hidden_size = 128 output_size = 1 batch_size = 16 # 定义神经网络模型 my_nn = torch.nn.Sequential( torch.nn.Linear(input_size, hidden_size), torch.nn.Sigmoid(), # 激活函数 torch.nn.Linear(hidden_size, output_size), ) # 定义损失函数和优化器 cost = torch.nn.MSELoss(reduction=&#34;mean&#34;) # 均方误差损失函数 optimizer = torch.optim.Adam(my_nn.parameters(), lr=0.001) # Adam优化器 # 训练神经网络 num_epochs = 1000 x = torch.tensor(input_features, dtype=torch.float) y = torch.tensor(labels, dtype=torch.float).view(-1, 1) for epoch in range(num_epochs): # 使用MINI-Batch方法进行训练 permutation = torch.randperm(x.size()[0]) for start in range(0, x.size()[0], batch_size): indices = permutation[start:start &#43; batch_size] batch_x, batch_y = x[indices], y[indices] # 前向传播 prediction = my_nn(batch_x) loss = cost(prediction, batch_y) # 梯度清零 optimizer.zero_grad() # 反向传播 loss.backward() # 更新参数 optimizer.step() # 打印损失 if epoch % 100 == 0: print(f&#39;Epoch: {epoch}, Loss: {loss.item()}&#39;) # 预测训练结果 predictions = my_nn(x).data.numpy() # 转化成numpy格式，方便绘图 " /><meta name="keywords" content="Hugo, theme, even" />


<meta name="robots" content="">






<meta name="generator" content="Hugo 0.136.5 with theme even" />


<link rel="canonical" href="https://inksnw.asuscomm.com:3001/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%80%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.64c9b7f0254ed1aa365dc8e9acbb5c7241025dced4946314569cf2cc3d7aa917.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"  crossorigin="anonymous">
<link rel="stylesheet" href="/css/styles.css">


<meta property="og:url" content="https://inksnw.asuscomm.com:3001/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%80%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/">
  <meta property="og:title" content="机器学习一:手写数字识别">
  <meta property="og:description" content="手写数字识别 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 import gzip import pickle import numpy as np import torch import torch.nn.functional as F from PIL import Image from torch import nn from torch import optim from torch.utils.data import DataLoader from torch.utils.data import TensorDataset from torchvision import transforms # https://raw.githubusercontent.com/mnielsen/neural-networks-and-deep-learning/master/data/mnist.pkl.gz # 从文件中加载数据 with gzip.open(&#34;mnist.pkl.gz&#34;, &#34;rb&#34;) as f: # 使用 pickle 加载数据，数据包括训练集、验证集和测试集 # 这里我们只加载了训练集和验证集 (x_train, y_train), (x_valid, y_valid), _ = pickle.load(f, encoding=&#34;latin-1&#34;) # 将加载的数据转换为 PyTorch 张量 x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid)) # 定义神经网络模型 class Mnist(nn.Module): def __init__(self): super().__init__() # 定义神经网络的层 self.hidden1 = nn.Linear(784, 128) # 隐藏层1，输入大小为 784，输出大小为 128 self.hidden2 = nn.Linear(128, 256) # 隐藏层2，输入大小为 128，输出大小为 256 self.out = nn.Linear(256, 10) # 输出层，输入大小为 256，输出大小为 10 self.dropout = nn.Dropout(0.5) # 定义 Dropout 层，丢弃概率为 0.5 def forward(self, x): # 定义数据流向 x = F.relu(self.hidden1(x)) # 使用 ReLU 激活函数 x = self.dropout(x) x = F.relu(self.hidden2(x)) x = self.dropout(x) x = self.out(x) return x # 定义训练函数 def fit(steps, loss_func, train_dl, valid_dl): # 创建神经网络模型 model = Mnist() # 定义优化器 opt = optim.Adam(model.parameters(), lr=0.001) for step in range(steps): model.train() # 将模型设置为训练模式 for xb, yb in train_dl: loss_batch(model, loss_func, xb, yb, opt) # 计算并更新模型参数 model.eval() # 将模型设置为评估模式 with torch.no_grad(): # 不更新权重参数 # 在验证集上进行评估 loss_result = [loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl] losses, nums = zip(*loss_result) val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums) correct = 0 total = 0 for xb, yb in valid_dl: outputs = model(xb) _, predicted = torch.max(outputs.data, 1) # 最大值和索引 total &#43;= yb.size(0) correct &#43;= (predicted == yb).sum().item() print(f&#34;当前step: {step}, 验证集损失: {val_loss} 准确率 {100 * correct / total}%&#34;) return model # 返回训练好的模型 # 定义计算损失的函数 def loss_batch(model, loss_func, xb, yb, opt=None): loss = loss_func(model(xb), yb) # 计算损失 if opt is not None: loss.backward() # 反向传播计算梯度 opt.step() # 更新模型权重参数 opt.zero_grad() # 梯度清零 return loss.item(), len(xb) # 定义预测函数 def predict(model, image_path): # 定义图像的预处理 transform = transforms.Compose([ transforms.Grayscale(), # 转为灰度图 transforms.Resize((28, 28)), # 调整大小为28x28 transforms.ToTensor(), # 转为张量 transforms.Normalize((0.5,), (0.5,)) # 归一化 ]) # 打开图像 img = Image.open(image_path) img = transform(img).unsqueeze(0) # 添加批次维度 # 将模型设置为评估模式 model.eval() with torch.no_grad(): output = model(img.view(-1, 28 * 28)) # 展平图像并进行预测 _, predicted = torch.max(output, 1) # 获取最大值对应的索引 return predicted.item() if __name__ == &#39;__main__&#39;: bs = 64 # 定义批量大小 # 创建训练集和验证集的 DataLoader 对象 train_dl = DataLoader(TensorDataset(x_train, y_train), batch_size=bs, shuffle=True) valid_dl = DataLoader(TensorDataset(x_valid, y_valid), batch_size=bs) # 训练模型 model = fit(25, F.cross_entropy, train_dl, valid_dl) # 保存模型参数 torch.save(model.state_dict(), &#39;mnist_model.pth&#39;) # 创建模型实例并加载训练好的模型参数 model = Mnist() model.load_state_dict(torch.load(&#39;mnist_model.pth&#39;)) # 预测手写数字图像 image_path = &#39;test.png&#39; # 替换为你要预测的图像路径 predicted_digit = predict(model, image_path) print(f&#39;预测的数字是: {predicted_digit}&#39;) 温度预测 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 import pandas as pd import torch from sklearn import preprocessing # 数据预处理模块 # https://github.com/DevCHyderabad/Data-Science/blob/master/ml_algorithms/randomForrest/temps.csv # 数据加载 features = pd.read_csv(&#34;temps.csv&#34;) # 将日期转换为datetime格式 dates = pd.to_datetime(features[[&#39;year&#39;, &#39;month&#39;, &#39;day&#39;]]) # 将分类特征转化为数值形式 features = pd.get_dummies(features) # 标签列 labels = features[&#34;actual&#34;].values # 在特征中去除标签列 features = features.drop(&#34;actual&#34;, axis=1) # 标准化特征数据 scaler = preprocessing.StandardScaler() input_features = scaler.fit_transform(features) # 转换数据格式为Tensor # 定义模型参数 input_size = input_features.shape[1] hidden_size = 128 output_size = 1 batch_size = 16 # 定义神经网络模型 my_nn = torch.nn.Sequential( torch.nn.Linear(input_size, hidden_size), torch.nn.Sigmoid(), # 激活函数 torch.nn.Linear(hidden_size, output_size), ) # 定义损失函数和优化器 cost = torch.nn.MSELoss(reduction=&#34;mean&#34;) # 均方误差损失函数 optimizer = torch.optim.Adam(my_nn.parameters(), lr=0.001) # Adam优化器 # 训练神经网络 num_epochs = 1000 x = torch.tensor(input_features, dtype=torch.float) y = torch.tensor(labels, dtype=torch.float).view(-1, 1) for epoch in range(num_epochs): # 使用MINI-Batch方法进行训练 permutation = torch.randperm(x.size()[0]) for start in range(0, x.size()[0], batch_size): indices = permutation[start:start &#43; batch_size] batch_x, batch_y = x[indices], y[indices] # 前向传播 prediction = my_nn(batch_x) loss = cost(prediction, batch_y) # 梯度清零 optimizer.zero_grad() # 反向传播 loss.backward() # 更新参数 optimizer.step() # 打印损失 if epoch % 100 == 0: print(f&#39;Epoch: {epoch}, Loss: {loss.item()}&#39;) # 预测训练结果 predictions = my_nn(x).data.numpy() # 转化成numpy格式，方便绘图">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-05-15T22:15:33+08:00">
    <meta property="article:modified_time" content="2024-05-15T22:15:33+08:00">
    <meta property="article:tag" content="Ai">

  <meta itemprop="name" content="机器学习一:手写数字识别">
  <meta itemprop="description" content="手写数字识别 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 import gzip import pickle import numpy as np import torch import torch.nn.functional as F from PIL import Image from torch import nn from torch import optim from torch.utils.data import DataLoader from torch.utils.data import TensorDataset from torchvision import transforms # https://raw.githubusercontent.com/mnielsen/neural-networks-and-deep-learning/master/data/mnist.pkl.gz # 从文件中加载数据 with gzip.open(&#34;mnist.pkl.gz&#34;, &#34;rb&#34;) as f: # 使用 pickle 加载数据，数据包括训练集、验证集和测试集 # 这里我们只加载了训练集和验证集 (x_train, y_train), (x_valid, y_valid), _ = pickle.load(f, encoding=&#34;latin-1&#34;) # 将加载的数据转换为 PyTorch 张量 x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid)) # 定义神经网络模型 class Mnist(nn.Module): def __init__(self): super().__init__() # 定义神经网络的层 self.hidden1 = nn.Linear(784, 128) # 隐藏层1，输入大小为 784，输出大小为 128 self.hidden2 = nn.Linear(128, 256) # 隐藏层2，输入大小为 128，输出大小为 256 self.out = nn.Linear(256, 10) # 输出层，输入大小为 256，输出大小为 10 self.dropout = nn.Dropout(0.5) # 定义 Dropout 层，丢弃概率为 0.5 def forward(self, x): # 定义数据流向 x = F.relu(self.hidden1(x)) # 使用 ReLU 激活函数 x = self.dropout(x) x = F.relu(self.hidden2(x)) x = self.dropout(x) x = self.out(x) return x # 定义训练函数 def fit(steps, loss_func, train_dl, valid_dl): # 创建神经网络模型 model = Mnist() # 定义优化器 opt = optim.Adam(model.parameters(), lr=0.001) for step in range(steps): model.train() # 将模型设置为训练模式 for xb, yb in train_dl: loss_batch(model, loss_func, xb, yb, opt) # 计算并更新模型参数 model.eval() # 将模型设置为评估模式 with torch.no_grad(): # 不更新权重参数 # 在验证集上进行评估 loss_result = [loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl] losses, nums = zip(*loss_result) val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums) correct = 0 total = 0 for xb, yb in valid_dl: outputs = model(xb) _, predicted = torch.max(outputs.data, 1) # 最大值和索引 total &#43;= yb.size(0) correct &#43;= (predicted == yb).sum().item() print(f&#34;当前step: {step}, 验证集损失: {val_loss} 准确率 {100 * correct / total}%&#34;) return model # 返回训练好的模型 # 定义计算损失的函数 def loss_batch(model, loss_func, xb, yb, opt=None): loss = loss_func(model(xb), yb) # 计算损失 if opt is not None: loss.backward() # 反向传播计算梯度 opt.step() # 更新模型权重参数 opt.zero_grad() # 梯度清零 return loss.item(), len(xb) # 定义预测函数 def predict(model, image_path): # 定义图像的预处理 transform = transforms.Compose([ transforms.Grayscale(), # 转为灰度图 transforms.Resize((28, 28)), # 调整大小为28x28 transforms.ToTensor(), # 转为张量 transforms.Normalize((0.5,), (0.5,)) # 归一化 ]) # 打开图像 img = Image.open(image_path) img = transform(img).unsqueeze(0) # 添加批次维度 # 将模型设置为评估模式 model.eval() with torch.no_grad(): output = model(img.view(-1, 28 * 28)) # 展平图像并进行预测 _, predicted = torch.max(output, 1) # 获取最大值对应的索引 return predicted.item() if __name__ == &#39;__main__&#39;: bs = 64 # 定义批量大小 # 创建训练集和验证集的 DataLoader 对象 train_dl = DataLoader(TensorDataset(x_train, y_train), batch_size=bs, shuffle=True) valid_dl = DataLoader(TensorDataset(x_valid, y_valid), batch_size=bs) # 训练模型 model = fit(25, F.cross_entropy, train_dl, valid_dl) # 保存模型参数 torch.save(model.state_dict(), &#39;mnist_model.pth&#39;) # 创建模型实例并加载训练好的模型参数 model = Mnist() model.load_state_dict(torch.load(&#39;mnist_model.pth&#39;)) # 预测手写数字图像 image_path = &#39;test.png&#39; # 替换为你要预测的图像路径 predicted_digit = predict(model, image_path) print(f&#39;预测的数字是: {predicted_digit}&#39;) 温度预测 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 import pandas as pd import torch from sklearn import preprocessing # 数据预处理模块 # https://github.com/DevCHyderabad/Data-Science/blob/master/ml_algorithms/randomForrest/temps.csv # 数据加载 features = pd.read_csv(&#34;temps.csv&#34;) # 将日期转换为datetime格式 dates = pd.to_datetime(features[[&#39;year&#39;, &#39;month&#39;, &#39;day&#39;]]) # 将分类特征转化为数值形式 features = pd.get_dummies(features) # 标签列 labels = features[&#34;actual&#34;].values # 在特征中去除标签列 features = features.drop(&#34;actual&#34;, axis=1) # 标准化特征数据 scaler = preprocessing.StandardScaler() input_features = scaler.fit_transform(features) # 转换数据格式为Tensor # 定义模型参数 input_size = input_features.shape[1] hidden_size = 128 output_size = 1 batch_size = 16 # 定义神经网络模型 my_nn = torch.nn.Sequential( torch.nn.Linear(input_size, hidden_size), torch.nn.Sigmoid(), # 激活函数 torch.nn.Linear(hidden_size, output_size), ) # 定义损失函数和优化器 cost = torch.nn.MSELoss(reduction=&#34;mean&#34;) # 均方误差损失函数 optimizer = torch.optim.Adam(my_nn.parameters(), lr=0.001) # Adam优化器 # 训练神经网络 num_epochs = 1000 x = torch.tensor(input_features, dtype=torch.float) y = torch.tensor(labels, dtype=torch.float).view(-1, 1) for epoch in range(num_epochs): # 使用MINI-Batch方法进行训练 permutation = torch.randperm(x.size()[0]) for start in range(0, x.size()[0], batch_size): indices = permutation[start:start &#43; batch_size] batch_x, batch_y = x[indices], y[indices] # 前向传播 prediction = my_nn(batch_x) loss = cost(prediction, batch_y) # 梯度清零 optimizer.zero_grad() # 反向传播 loss.backward() # 更新参数 optimizer.step() # 打印损失 if epoch % 100 == 0: print(f&#39;Epoch: {epoch}, Loss: {loss.item()}&#39;) # 预测训练结果 predictions = my_nn(x).data.numpy() # 转化成numpy格式，方便绘图">
  <meta itemprop="datePublished" content="2024-05-15T22:15:33+08:00">
  <meta itemprop="dateModified" content="2024-05-15T22:15:33+08:00">
  <meta itemprop="wordCount" content="1306">
  <meta itemprop="keywords" content="Ai">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="机器学习一:手写数字识别">
  <meta name="twitter:description" content="手写数字识别 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 import gzip import pickle import numpy as np import torch import torch.nn.functional as F from PIL import Image from torch import nn from torch import optim from torch.utils.data import DataLoader from torch.utils.data import TensorDataset from torchvision import transforms # https://raw.githubusercontent.com/mnielsen/neural-networks-and-deep-learning/master/data/mnist.pkl.gz # 从文件中加载数据 with gzip.open(&#34;mnist.pkl.gz&#34;, &#34;rb&#34;) as f: # 使用 pickle 加载数据，数据包括训练集、验证集和测试集 # 这里我们只加载了训练集和验证集 (x_train, y_train), (x_valid, y_valid), _ = pickle.load(f, encoding=&#34;latin-1&#34;) # 将加载的数据转换为 PyTorch 张量 x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid)) # 定义神经网络模型 class Mnist(nn.Module): def __init__(self): super().__init__() # 定义神经网络的层 self.hidden1 = nn.Linear(784, 128) # 隐藏层1，输入大小为 784，输出大小为 128 self.hidden2 = nn.Linear(128, 256) # 隐藏层2，输入大小为 128，输出大小为 256 self.out = nn.Linear(256, 10) # 输出层，输入大小为 256，输出大小为 10 self.dropout = nn.Dropout(0.5) # 定义 Dropout 层，丢弃概率为 0.5 def forward(self, x): # 定义数据流向 x = F.relu(self.hidden1(x)) # 使用 ReLU 激活函数 x = self.dropout(x) x = F.relu(self.hidden2(x)) x = self.dropout(x) x = self.out(x) return x # 定义训练函数 def fit(steps, loss_func, train_dl, valid_dl): # 创建神经网络模型 model = Mnist() # 定义优化器 opt = optim.Adam(model.parameters(), lr=0.001) for step in range(steps): model.train() # 将模型设置为训练模式 for xb, yb in train_dl: loss_batch(model, loss_func, xb, yb, opt) # 计算并更新模型参数 model.eval() # 将模型设置为评估模式 with torch.no_grad(): # 不更新权重参数 # 在验证集上进行评估 loss_result = [loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl] losses, nums = zip(*loss_result) val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums) correct = 0 total = 0 for xb, yb in valid_dl: outputs = model(xb) _, predicted = torch.max(outputs.data, 1) # 最大值和索引 total &#43;= yb.size(0) correct &#43;= (predicted == yb).sum().item() print(f&#34;当前step: {step}, 验证集损失: {val_loss} 准确率 {100 * correct / total}%&#34;) return model # 返回训练好的模型 # 定义计算损失的函数 def loss_batch(model, loss_func, xb, yb, opt=None): loss = loss_func(model(xb), yb) # 计算损失 if opt is not None: loss.backward() # 反向传播计算梯度 opt.step() # 更新模型权重参数 opt.zero_grad() # 梯度清零 return loss.item(), len(xb) # 定义预测函数 def predict(model, image_path): # 定义图像的预处理 transform = transforms.Compose([ transforms.Grayscale(), # 转为灰度图 transforms.Resize((28, 28)), # 调整大小为28x28 transforms.ToTensor(), # 转为张量 transforms.Normalize((0.5,), (0.5,)) # 归一化 ]) # 打开图像 img = Image.open(image_path) img = transform(img).unsqueeze(0) # 添加批次维度 # 将模型设置为评估模式 model.eval() with torch.no_grad(): output = model(img.view(-1, 28 * 28)) # 展平图像并进行预测 _, predicted = torch.max(output, 1) # 获取最大值对应的索引 return predicted.item() if __name__ == &#39;__main__&#39;: bs = 64 # 定义批量大小 # 创建训练集和验证集的 DataLoader 对象 train_dl = DataLoader(TensorDataset(x_train, y_train), batch_size=bs, shuffle=True) valid_dl = DataLoader(TensorDataset(x_valid, y_valid), batch_size=bs) # 训练模型 model = fit(25, F.cross_entropy, train_dl, valid_dl) # 保存模型参数 torch.save(model.state_dict(), &#39;mnist_model.pth&#39;) # 创建模型实例并加载训练好的模型参数 model = Mnist() model.load_state_dict(torch.load(&#39;mnist_model.pth&#39;)) # 预测手写数字图像 image_path = &#39;test.png&#39; # 替换为你要预测的图像路径 predicted_digit = predict(model, image_path) print(f&#39;预测的数字是: {predicted_digit}&#39;) 温度预测 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 import pandas as pd import torch from sklearn import preprocessing # 数据预处理模块 # https://github.com/DevCHyderabad/Data-Science/blob/master/ml_algorithms/randomForrest/temps.csv # 数据加载 features = pd.read_csv(&#34;temps.csv&#34;) # 将日期转换为datetime格式 dates = pd.to_datetime(features[[&#39;year&#39;, &#39;month&#39;, &#39;day&#39;]]) # 将分类特征转化为数值形式 features = pd.get_dummies(features) # 标签列 labels = features[&#34;actual&#34;].values # 在特征中去除标签列 features = features.drop(&#34;actual&#34;, axis=1) # 标准化特征数据 scaler = preprocessing.StandardScaler() input_features = scaler.fit_transform(features) # 转换数据格式为Tensor # 定义模型参数 input_size = input_features.shape[1] hidden_size = 128 output_size = 1 batch_size = 16 # 定义神经网络模型 my_nn = torch.nn.Sequential( torch.nn.Linear(input_size, hidden_size), torch.nn.Sigmoid(), # 激活函数 torch.nn.Linear(hidden_size, output_size), ) # 定义损失函数和优化器 cost = torch.nn.MSELoss(reduction=&#34;mean&#34;) # 均方误差损失函数 optimizer = torch.optim.Adam(my_nn.parameters(), lr=0.001) # Adam优化器 # 训练神经网络 num_epochs = 1000 x = torch.tensor(input_features, dtype=torch.float) y = torch.tensor(labels, dtype=torch.float).view(-1, 1) for epoch in range(num_epochs): # 使用MINI-Batch方法进行训练 permutation = torch.randperm(x.size()[0]) for start in range(0, x.size()[0], batch_size): indices = permutation[start:start &#43; batch_size] batch_x, batch_y = x[indices], y[indices] # 前向传播 prediction = my_nn(batch_x) loss = cost(prediction, batch_y) # 梯度清零 optimizer.zero_grad() # 反向传播 loss.backward() # 更新参数 optimizer.step() # 打印损失 if epoch % 100 == 0: print(f&#39;Epoch: {epoch}, Loss: {loss.item()}&#39;) # 预测训练结果 predictions = my_nn(x).data.numpy() # 转化成numpy格式，方便绘图">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo"></a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">首页</li>
      </a><a href="/rust/">
        <li class="mobile-menu-item">rust</li>
      </a><a href="/life/">
        <li class="mobile-menu-item">生活</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo"></a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">首页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/rust/">rust</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/life/">生活</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    

    <header class="post-header">
        <h1 class="post-title">机器学习一:手写数字识别</h1>

        <div class="post-meta">
            <span class="post-time"> 2024-05-15 </span>
            
            <span class="more-meta"> 约 1306 字 更新于 2024-05-15
              <a class="article-tags" href=/tags/ai/>ai</a>
                </span>
            
        </div>
    </header>

    
<div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">目录</h2>
    <div class="post-toc-content always-active">
        <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#手写数字识别">手写数字识别</a></li>
        <li><a href="#温度预测">温度预测</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>
</div>

    
    <div class="post-content">
        <h2 id="手写数字识别">手写数字识别</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">gzip</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pickle</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># https://raw.githubusercontent.com/mnielsen/neural-networks-and-deep-learning/master/data/mnist.pkl.gz</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 从文件中加载数据</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&#34;mnist.pkl.gz&#34;</span><span class="p">,</span> <span class="s2">&#34;rb&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 使用 pickle 加载数据，数据包括训练集、验证集和测试集</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 这里我们只加载了训练集和验证集</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&#34;latin-1&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 将加载的数据转换为 PyTorch 张量</span>
</span></span><span class="line"><span class="cl"><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 定义神经网络模型</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Mnist</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 定义神经网络的层</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">hidden1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>  <span class="c1"># 隐藏层1，输入大小为 784，输出大小为 128</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">hidden2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>  <span class="c1"># 隐藏层2，输入大小为 128，输出大小为 256</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># 输出层，输入大小为 256，输出大小为 10</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>  <span class="c1"># 定义 Dropout 层，丢弃概率为 0.5</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 定义数据流向</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>  <span class="c1"># 使用 ReLU 激活函数</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">x</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 定义训练函数</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">train_dl</span><span class="p">,</span> <span class="n">valid_dl</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 创建神经网络模型</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">Mnist</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 定义优化器</span>
</span></span><span class="line"><span class="cl">    <span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># 将模型设置为训练模式</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">loss_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>  <span class="c1"># 计算并更新模型参数</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># 将模型设置为评估模式</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># 不更新权重参数</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 在验证集上进行评估</span>
</span></span><span class="line"><span class="cl">            <span class="n">loss_result</span> <span class="o">=</span> <span class="p">[</span><span class="n">loss_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span> <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">valid_dl</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">losses</span><span class="p">,</span> <span class="n">nums</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">loss_result</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">nums</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">nums</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">valid_dl</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># 最大值和索引</span>
</span></span><span class="line"><span class="cl">            <span class="n">total</span> <span class="o">+=</span> <span class="n">yb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">yb</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;当前step: </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">, 验证集损失: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">}</span><span class="s2"> 准确率 </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="si">}</span><span class="s2">%&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model</span>  <span class="c1"># 返回训练好的模型</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 定义计算损失的函数</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">loss_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">opt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">),</span> <span class="n">yb</span><span class="p">)</span>  <span class="c1"># 计算损失</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">opt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># 反向传播计算梯度</span>
</span></span><span class="line"><span class="cl">        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># 更新模型权重参数</span>
</span></span><span class="line"><span class="cl">        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1"># 梯度清零</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 定义预测函数</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">image_path</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 定义图像的预处理</span>
</span></span><span class="line"><span class="cl">    <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">        <span class="n">transforms</span><span class="o">.</span><span class="n">Grayscale</span><span class="p">(),</span>  <span class="c1"># 转为灰度图</span>
</span></span><span class="line"><span class="cl">        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>  <span class="c1"># 调整大小为28x28</span>
</span></span><span class="line"><span class="cl">        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>  <span class="c1"># 转为张量</span>
</span></span><span class="line"><span class="cl">        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,))</span>  <span class="c1"># 归一化</span>
</span></span><span class="line"><span class="cl">    <span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 打开图像</span>
</span></span><span class="line"><span class="cl">    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">img</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 添加批次维度</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 将模型设置为评估模式</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>  <span class="c1"># 展平图像并进行预测</span>
</span></span><span class="line"><span class="cl">        <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># 获取最大值对应的索引</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">predicted</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">bs</span> <span class="o">=</span> <span class="mi">64</span>  <span class="c1"># 定义批量大小</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 创建训练集和验证集的 DataLoader 对象</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">bs</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">valid_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">bs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 训练模型</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">fit</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">,</span> <span class="n">train_dl</span><span class="p">,</span> <span class="n">valid_dl</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 保存模型参数</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;mnist_model.pth&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 创建模型实例并加载训练好的模型参数</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">Mnist</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;mnist_model.pth&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 预测手写数字图像</span>
</span></span><span class="line"><span class="cl">    <span class="n">image_path</span> <span class="o">=</span> <span class="s1">&#39;test.png&#39;</span>  <span class="c1"># 替换为你要预测的图像路径</span>
</span></span><span class="line"><span class="cl">    <span class="n">predicted_digit</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">image_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;预测的数字是: </span><span class="si">{</span><span class="n">predicted_digit</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="温度预测">温度预测</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>  <span class="c1"># 数据预处理模块</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># https://github.com/DevCHyderabad/Data-Science/blob/master/ml_algorithms/randomForrest/temps.csv</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 数据加载</span>
</span></span><span class="line"><span class="cl"><span class="n">features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&#34;temps.csv&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 将日期转换为datetime格式</span>
</span></span><span class="line"><span class="cl"><span class="n">dates</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">features</span><span class="p">[[</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="s1">&#39;month&#39;</span><span class="p">,</span> <span class="s1">&#39;day&#39;</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 将分类特征转化为数值形式</span>
</span></span><span class="line"><span class="cl"><span class="n">features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 标签列</span>
</span></span><span class="line"><span class="cl"><span class="n">labels</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="s2">&#34;actual&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 在特征中去除标签列</span>
</span></span><span class="line"><span class="cl"><span class="n">features</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;actual&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 标准化特征数据</span>
</span></span><span class="line"><span class="cl"><span class="n">scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">input_features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 转换数据格式为Tensor</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 定义模型参数</span>
</span></span><span class="line"><span class="cl"><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">128</span>
</span></span><span class="line"><span class="cl"><span class="n">output_size</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 定义神经网络模型</span>
</span></span><span class="line"><span class="cl"><span class="n">my_nn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>  <span class="c1"># 激活函数</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">),</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 定义损失函数和优化器</span>
</span></span><span class="line"><span class="cl"><span class="n">cost</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s2">&#34;mean&#34;</span><span class="p">)</span>  <span class="c1"># 均方误差损失函数</span>
</span></span><span class="line"><span class="cl"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">my_nn</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>  <span class="c1"># Adam优化器</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 训练神经网络</span>
</span></span><span class="line"><span class="cl"><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">1000</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_features</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 使用MINI-Batch方法进行训练</span>
</span></span><span class="line"><span class="cl">    <span class="n">permutation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">start</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">indices</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">start</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 前向传播</span>
</span></span><span class="line"><span class="cl">        <span class="n">prediction</span> <span class="o">=</span> <span class="n">my_nn</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span> <span class="o">=</span> <span class="n">cost</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 梯度清零</span>
</span></span><span class="line"><span class="cl">        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 反向传播</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 更新参数</span>
</span></span><span class="line"><span class="cl">        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 打印损失</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 预测训练结果</span>
</span></span><span class="line"><span class="cl"><span class="n">predictions</span> <span class="o">=</span> <span class="n">my_nn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># 转化成numpy格式，方便绘图</span>
</span></span></code></pre></td></tr></table>
</div>
</div>
    </div>

    
<footer class="post-footer">
        <div class="post-tags">
            <a href="/tags/ai/">ai</a>
            </div>
        <nav class="post-nav">
            <a class="prev" href="/post/webhook%E7%94%9F%E6%88%90%E8%AF%81%E4%B9%A6/">
                <i class="iconfont icon-left"></i>
                <span class="prev-text nav-default">Webhook生成证书</span>
                <span class="prev-text nav-mobile">上一篇</span>
            </a>
            <a class="next" href="/post/go-containerregistry%E5%BA%93%E7%9A%84%E4%B8%80%E4%B8%AA%E5%B0%8F%E5%9D%91/">
                <span class="next-text nav-default">Go Containerregistry库的一个小坑</span>
                <span class="next-text nav-mobile">下一篇</span>
                <i class="iconfont icon-right"></i>
            </a>
        </nav>
    </footer>
</article>
        </div>
        

  

  

  
  

      </div>
    </main>

    <footer id="footer" class="footer">
      
<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 -
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy;
    2022 -
    2024<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"  crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/slideout/1.0.1/slideout.min.js"  crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>






<script src="/js/scripts.js"></script>


</body>
</html>
